Homework2
================
Xicheng Xie
2022-10-03

### Problem 0

This solution focuses on a reproducible report containing code and text
necessary for Problems 1-3, and is organized as an R Project.

``` r
library(tidyverse)
```

    ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──
    ## ✔ ggplot2 3.3.6      ✔ purrr   0.3.4 
    ## ✔ tibble  3.1.8      ✔ dplyr   1.0.10
    ## ✔ tidyr   1.2.0      ✔ stringr 1.4.1 
    ## ✔ readr   2.1.2      ✔ forcats 0.5.2 
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()

``` r
library(readxl)
library(lubridate)
```

    ## 
    ## Attaching package: 'lubridate'
    ## 
    ## The following objects are masked from 'package:base':
    ## 
    ##     date, intersect, setdiff, union

### Problem 1

Below we import and clean data from
`NYC_Transit_Subway_Entrance_And_Exit_Data.csv`. The process begins with
data import, updates variable names, and selects the columns that will
be used in later parts fo this problem. We update `entry` from `yes` /
`no` to a logical variable. As part of data import, we specify that
`Route` columns 8-11 should be character for consistency with 1-7.

``` r
trans_ent = 
  read_csv(
    "data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>% 
  janitor::clean_names() %>% 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

As it stands, these data are not “tidy”: route number should be a
variable, as should route. That is, to obtain a tidy dataset we would
need to convert `route` variables from wide to long format. This will be
useful when focusing on specific routes, but may not be necessary when
considering questions that focus on station-level variables.

# question 1

The following code chunk selects station name and line, and then uses
`distinct()` to obtain all unique combinations. As a result, the number
of rows in this dataset is the number of unique stations, which is
**465**.

``` r
trans_ent %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 465 × 2
    ##    station_name             line    
    ##    <chr>                    <chr>   
    ##  1 25th St                  4 Avenue
    ##  2 36th St                  4 Avenue
    ##  3 45th St                  4 Avenue
    ##  4 53rd St                  4 Avenue
    ##  5 59th St                  4 Avenue
    ##  6 77th St                  4 Avenue
    ##  7 86th St                  4 Avenue
    ##  8 95th St                  4 Avenue
    ##  9 9th St                   4 Avenue
    ## 10 Atlantic Av-Barclays Ctr 4 Avenue
    ## # … with 455 more rows

# question 2

The next code chunk is similar, but filters according to ADA compliance
as an initial step. This produces a dataframe in which the number of
rows is the number of ADA compliant stations.

``` r
trans_ent %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 84 × 2
    ##    station_name                   line           
    ##    <chr>                          <chr>          
    ##  1 Atlantic Av-Barclays Ctr       4 Avenue       
    ##  2 DeKalb Av                      4 Avenue       
    ##  3 Pacific St                     4 Avenue       
    ##  4 Grand Central                  42nd St Shuttle
    ##  5 34th St                        6 Avenue       
    ##  6 47-50th Sts Rockefeller Center 6 Avenue       
    ##  7 Church Av                      6 Avenue       
    ##  8 21st St                        63rd Street    
    ##  9 Lexington Av                   63rd Street    
    ## 10 Roosevelt Island               63rd Street    
    ## # … with 74 more rows

# question 3

To compute the proportion of station entrances / exits without vending
allow entrance, we first exclude station entrances that do not allow
vending. Then, we focus on the `entry` variable – this logical, so
taking the mean will produce the desired proportion (recall that R will
coerce logical to numeric in cases like this).

``` r
trans_ent %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
```

    ## [1] 0.3770492

# question 4

Lastly, we write a code chunk to identify stations that serve the A
train, and to assess how many of these are ADA compliant. As a first
step, we tidy the data as alluded to previously; that is, we convert
`route` from wide to long format. After this step, we can use tools from
previous parts of the question (filtering to focus on the A train, and
on ADA compliance; selecting and using `distinct` to obtain dataframes
with the required stations in rows).

``` r
trans_ent %>% 
  pivot_longer(
    starts_with("route"),
    names_to = "route_number",
    values_to = "route") %>% 
  filter(route =="A") %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 60 × 2
    ##    station_name                  line           
    ##    <chr>                         <chr>          
    ##  1 Times Square                  42nd St Shuttle
    ##  2 125th St                      8 Avenue       
    ##  3 145th St                      8 Avenue       
    ##  4 14th St                       8 Avenue       
    ##  5 168th St - Washington Heights 8 Avenue       
    ##  6 175th St                      8 Avenue       
    ##  7 181st St                      8 Avenue       
    ##  8 190th St                      8 Avenue       
    ##  9 34th St                       8 Avenue       
    ## 10 42nd St                       8 Avenue       
    ## # … with 50 more rows

``` r
trans_ent %>% 
  pivot_longer(
    starts_with("route"),
    names_to = "route_number",
    values_to = "route") %>% 
  filter(route =="A",ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 17 × 2
    ##    station_name                  line            
    ##    <chr>                         <chr>           
    ##  1 14th St                       8 Avenue        
    ##  2 168th St - Washington Heights 8 Avenue        
    ##  3 175th St                      8 Avenue        
    ##  4 34th St                       8 Avenue        
    ##  5 42nd St                       8 Avenue        
    ##  6 59th St                       8 Avenue        
    ##  7 Inwood - 207th St             8 Avenue        
    ##  8 West 4th St                   8 Avenue        
    ##  9 World Trade Center            8 Avenue        
    ## 10 Times Square-42nd St          Broadway        
    ## 11 59th St-Columbus Circle       Broadway-7th Ave
    ## 12 Times Square                  Broadway-7th Ave
    ## 13 8th Av                        Canarsie        
    ## 14 Franklin Av                   Franklin        
    ## 15 Euclid Av                     Fulton          
    ## 16 Franklin Av                   Fulton          
    ## 17 Howard Beach                  Rockaway

### Problem 2

\#First, we read and clean the Mr. Trash Wheel sheet and Professor Trash
Wheel sheet: *specify the sheet in the Excel file and to omit non-data
entries (rows with notes / figures; columns containing notes) using
arguments in read_excel *use reasonable variable names *omit rows that
do not include dumpster-specific data *round the number of sports balls
to the nearest integer and converts the result to an integer variable
(using as.integer) Meanwhile, to keep track of which Trash Wheel is
which, we add an additional variable called **wheel_type** to both
datasets before combining.

``` r
Mr.trash_wheel<-
  read_excel("data/Trash Wheel Collection Data.xlsx",sheet = "Mr. Trash Wheel",range = "A2:N549") %>%
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  filter(!(dumpster=="Grand Total")) %>% 
  mutate(sports_balls = as.integer(sports_balls),wheel_type="Mr.trash_wheel")

Professor_trash_wheel<-
  read_excel("data/Trash Wheel Collection Data.xlsx",sheet = "Professor Trash Wheel",range = "A2:N96") %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(sports_balls = NA,year=as.character(year),wheel_type="Professor_trash_wheel") %>% 
  select(-x14)
```

    ## New names:
    ## • `` -> `...14`

\#Then we combine these two datasets togather We use `bind_rows` to
combine these two datasets and name the new dataset **Trash_wheel**

``` r
Trash_wheel<-
  bind_rows(Mr.trash_wheel,Professor_trash_wheel) %>% 
  janitor::clean_names() %>% 
  select(wheel_type,everything())
```

\#Write a paragraph about these data In the Trash_wheel, there are
641rows and 15columns with variables related to the trash collected by
the Trash Wheel. In the chunk below, the total weight of trash and the
total number of sports balls collected by Mr. Trash Wheel and Professor
Trash Wheel are computed intuitively. The total weight of trash
collected by Professor Trash Wheel is 190.12.The total number of sports
balls collected by Mr.Trash Wheel in 2020 is 530.

``` r
by_trash_wheel<-Trash_wheel %>% 
  group_by(wheel_type) %>% 
  summarise(
    weight_sum=sum(weight_tons),
    n_sports_balls=sum(sports_balls)
  )
```

### Problem 3

This problem uses the **FiveThirtyEight** data. In particular, we’ll use
the data in pols-month.csv, unemployment.csv, and snp.csv. Our goal is
to merge these into a single data frame using year and month as keys
across datasets.

\#First, clean the data in pols-month.csv We first use `separate()`to
break the variable `mon`, and then `month.abb` is applied to mutate the
month number to month name. We use `recode`to create a new variable
taking values `gop` and `dem`.

``` r
pols_month<-
  read.csv("data/fivethirtyeight_datasets/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(mon,c("year","month","day"),sep = "-",convert = TRUE) %>%
  mutate(month=month.abb[month]) %>%
  mutate(president=recode(prez_gop,`1`="gop",`0`="dem"),president=factor(president))%>%
  select(-day, -prez_gop, - prez_dem) %>% 
  select(year,month,president,everything())
```

\#Second, clean the data in snp.csv using a similar process to the
above. This time the date is kind of tricky. The `date` presents %m%d%y
format and the year is 2 digits, not 4 digits, which means that we will
only get 2 digit int of the year by only applying `separate`. Hence, we
use `parse_data_time` first to convert the date variable into
**POSIXct** date-time object, and the following process is similar to
the above.

``` r
df_snp<-
  read.csv("data/fivethirtyeight_datasets/snp.csv") %>% 
  janitor::clean_names() %>%
  mutate(date=parse_date_time(date,"%m/%d/%y")) %>% 
  separate(date,c("year","month","day"),sep = "-",convert = TRUE) %>% 
  arrange(year,month) %>%
  mutate(month = month.abb[month])%>%
  select(year,month,-day,everything()) %>% 
  select(-day)
```

\#Third, tidy the unemployment data so that it can be merged with the
previous datasets. We use `pivot_longer` function to switch the format
of the dataset.

``` r
df_unemploy<-
  read.csv("data/fivethirtyeight_datasets/unemployment.csv") %>% 
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "pct_unemploy"
  ) %>% 
  janitor::clean_names()
```

\#Join the datasets by merging snp into pols, and merging unemployment
into the result.

``` r
df_pols_snp<-left_join(pols_month,df_snp,by=c("year","month"))
df_total<-left_join(df_pols_snp,df_unemploy,by=c("year","month"))
```

-   In the dataset `pols_month`, there are 822 rows and 9 columns. Key
    variables are time variables including `year` and `month`. The range
    of the year is 1947, 2015. Other variables including *gov_gop*: the
    number of republican governors on the associated date, *sen_gop*:
    the number of republican senators on the associated date, *rep_gop*:
    the number of republican representatives on the associated date,
    *gov_dem*: the number of democratic governors on the associated
    date, *sen_dem*: the number of democratic senators on the associated
    date, *rep_dem*: the number of democratic representatives on the
    associated date.

-   In the dataset `df_snp`, there are 787 rows and 3 columns. Key
    variables are `year`, which range from 1969, 2068, `month`, and
    `close`, which contains the closing values of the S&P stock index on
    the associated date.

-   In the datset `df_unemploy`, there are 816 rows and 3 columns. Key
    variables include `year` ranging in 1948, 2015, `month`, and
    `pct_unemploy` which contains the the percentage of unemployment of
    the associated month and year.

-   In the final version of dataset `df_total`, there are 822 rows and
    11 columns. Since we keep using `left_join()` function, the column
    number and variables like year and month all equal those in the
    dataset `pols_month`.
