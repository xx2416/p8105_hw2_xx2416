---
title: "Homework2"
author: "Xicheng Xie"
date: "2022-10-03"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Problem 0

This solution focuses on a reproducible report containing code and text necessary for Problems 1-3, and is organized as an R Project. 

```{r load_libraries}
library(tidyverse)
library(readxl)
library(lubridate)
```

### Problem 1

Below we import and clean data from `NYC_Transit_Subway_Entrance_And_Exit_Data.csv`. The process begins with data import, updates variable names, and selects the columns that will be used in later parts fo this problem. We update `entry` from `yes` / `no` to a logical variable. As part of data import, we specify that `Route` columns 8-11 should be character for consistency with 1-7.

```{r}
trans_ent = 
  read_csv(
    "data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>% 
  janitor::clean_names() %>% 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

As it stands, these data are not "tidy": route number should be a variable, as should route. That is, to obtain a tidy dataset we would need to convert `route` variables from wide to long format. This will be useful when focusing on specific routes, but may not be necessary when considering questions that focus on station-level variables. 

# question 1
The following code chunk selects station name and line, and then uses `distinct()` to obtain all unique combinations. As a result, the number of rows in this dataset is the number of unique stations, which is **465**.
```{r}
trans_ent %>% 
  select(station_name, line) %>% 
  distinct
```
# question 2
The next code chunk is similar, but filters according to ADA compliance as an initial step. This produces a dataframe in which the number of rows is the number of ADA compliant stations. 

```{r}
trans_ent %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```
# question 3
To compute the proportion of station entrances / exits without vending allow entrance, we first exclude station entrances that do not allow vending. Then, we focus on the `entry` variable -- this logical, so taking the mean will produce the desired proportion (recall that R will coerce logical to numeric in cases like this).
```{r}
trans_ent %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
```
# question 4
Lastly, we write a code chunk to identify stations that serve the A train, and to assess how many of these are ADA compliant. As a first step, we tidy the data as alluded to previously; that is, we convert `route` from wide to long format. After this step, we can use tools from previous parts of the question (filtering to focus on the A train, and on ADA compliance; selecting and using `distinct` to obtain dataframes with the required stations in rows).
```{r}
trans_ent %>% 
  pivot_longer(
    starts_with("route"),
    names_to = "route_number",
    values_to = "route") %>% 
  filter(route =="A") %>% 
  select(station_name, line) %>% 
  distinct

trans_ent %>% 
  pivot_longer(
    starts_with("route"),
    names_to = "route_number",
    values_to = "route") %>% 
  filter(route =="A",ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

### Problem 2

#First, we read and clean the Mr. Trash Wheel sheet and Professor Trash Wheel sheet:
*specify the sheet in the Excel file and to omit non-data entries (rows with notes / figures; columns containing notes) using arguments in read_excel
*use reasonable variable names
*omit rows that do not include dumpster-specific data
*round the number of sports balls to the nearest integer and converts the result to an integer variable (using as.integer)
Meanwhile, to keep track of which Trash Wheel is which, we add an additional variable called **wheel_type** to both datasets before combining.
```{r}
Mr.trash_wheel<-
  read_excel("data/Trash Wheel Collection Data.xlsx",sheet = "Mr. Trash Wheel",range = "A2:N549") %>%
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  filter(!(dumpster=="Grand Total")) %>% 
  mutate(sports_balls = as.integer(sports_balls),wheel_type="Mr.trash_wheel")

Professor_trash_wheel<-
  read_excel("data/Trash Wheel Collection Data.xlsx",sheet = "Professor Trash Wheel",range = "A2:N96") %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(sports_balls = NA,year=as.character(year),wheel_type="Professor_trash_wheel") %>% 
  select(-x14)
```
#Then we combine these two datasets togather
We use `bind_rows` to combine these two datasets and name the new dataset **Trash_wheel**
```{r}
Trash_wheel<-
  bind_rows(Mr.trash_wheel,Professor_trash_wheel) %>% 
  janitor::clean_names() %>% 
  select(wheel_type,everything())
```
#Write a paragraph about these data
In the Trash_wheel, there are `r nrow(Trash_wheel)`rows and `r ncol(Trash_wheel)`columns with variables related to the trash collected by the Trash Wheel. In the chunk below, the total weight of trash and the total number of sports balls collected by Mr. Trash Wheel and Professor Trash Wheel are computed intuitively. The total weight of trash collected by Professor Trash Wheel is `r sum(pull(Trash_wheel %>% filter(wheel_type=="Professor_trash_wheel"),weight_tons))`.The total number of sports balls collected by Mr.Trash Wheel in 2020 is `r sum(pull(Trash_wheel %>% filter(wheel_type=="Mr.trash_wheel",year==2017),sports_balls))`.
```{r}
by_trash_wheel<-Trash_wheel %>% 
  group_by(wheel_type) %>% 
  summarise(
    weight_sum=sum(weight_tons),
    n_sports_balls=sum(sports_balls)
  )
```

### Problem 3
This problem uses the **FiveThirtyEight** data. In particular, weâ€™ll use the data in pols-month.csv, unemployment.csv, and snp.csv. Our goal is to merge these into a single data frame using year and month as keys across datasets.

#First, clean the data in pols-month.csv
We first use `separate()`to break the variable `mon`, and then `month.abb` is applied to mutate the month number to month name. We use `recode`to create a new variable taking values `gop` and `dem`. 
```{r warning = FALSE}
pols_month<-
  read.csv("data/fivethirtyeight_datasets/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(mon,c("year","month","day"),sep = "-",convert = TRUE) %>%
  mutate(month=month.abb[month]) %>%
  mutate(president=recode(prez_gop,`1`="gop",`0`="dem"),president=factor(president))%>%
  select(-day, -prez_gop, - prez_dem) %>% 
  select(year,month,president,everything())
```
#Second, clean the data in snp.csv using a similar process to the above. 
This time the date is kind of tricky. The `date` presents %m%d%y format and the year is 2 digits, not 4 digits, which means that we will only get 2 digit int of the year by only applying `separate`. Hence, we use `parse_data_time` first to convert the date variable into POSIXct date-time object, and the following process is similar to the above.
```{r warning = FALSE}
df_snp<-
  read.csv("data/fivethirtyeight_datasets/snp.csv") %>% 
  janitor::clean_names() %>%
  mutate(date=parse_date_time(date,"%m/%d/%y")) %>% 
  separate(date,c("year","month","day"),sep = "-",convert = TRUE) %>% 
  arrange(year,month) %>%
  mutate(month = month.abb[month])%>%
  select(year,month,-day,everything())
```

#Third, tidy the unemployment data so that it can be merged with the previous datasets.
We use `pivot_longer` function to switch the format of the dataset.
```{r}
df_unemploy<-
  read.csv("data/fivethirtyeight_datasets/unemployment.csv") %>% 
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "pct_unemploy"
  ) 
  
```
#Join the datasets by merging snp into pols, and merging unemployment into the result.

